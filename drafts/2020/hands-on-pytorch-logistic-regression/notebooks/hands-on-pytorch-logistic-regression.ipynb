{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from IPython.core.display import HTML\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   sepal.length  sepal.width  petal.length  petal.width variety\n0           5.1          3.5           1.4          0.2  Setosa\n1           4.9          3.0           1.4          0.2  Setosa\n2           4.7          3.2           1.3          0.2  Setosa\n3           4.6          3.1           1.5          0.2  Setosa\n4           5.0          3.6           1.4          0.2  Setosa\nVirginica     50\nSetosa        50\nVersicolor    50\nName: variety, dtype: int64\n['Setosa', 'Versicolor', 'Virginica']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       sepal.length  sepal.width  petal.length  petal.width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.057333      3.758000     1.199333\n",
       "std        0.828066     0.435866      1.765298     0.762238\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal.length</th>\n      <th>sepal.width</th>\n      <th>petal.length</th>\n      <th>petal.width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.843333</td>\n      <td>3.057333</td>\n      <td>3.758000</td>\n      <td>1.199333</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.828066</td>\n      <td>0.435866</td>\n      <td>1.765298</td>\n      <td>0.762238</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.300000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.100000</td>\n      <td>2.800000</td>\n      <td>1.600000</td>\n      <td>0.300000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.800000</td>\n      <td>3.000000</td>\n      <td>4.350000</td>\n      <td>1.300000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.400000</td>\n      <td>3.300000</td>\n      <td>5.100000</td>\n      <td>1.800000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.900000</td>\n      <td>4.400000</td>\n      <td>6.900000</td>\n      <td>2.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "\n",
    "iris = pd.read_csv('iris.csv')\n",
    "print(iris.head())\n",
    "\n",
    "species = list(iris[\"variety\"].unique())\n",
    "print(iris['variety'].value_counts())\n",
    "\n",
    "print(species)\n",
    "iris.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>                        <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"76dc2767-b96d-47fd-9e4a-fb75b54e6007\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"76dc2767-b96d-47fd-9e4a-fb75b54e6007\")) {                    Plotly.newPlot(                        \"76dc2767-b96d-47fd-9e4a-fb75b54e6007\",                        [{\"hovertemplate\": \"variety=Setosa<br>sepal.length=%{x}<br>sepal.width=%{y}<br>petal.width=%{z}<br>petal.length=%{marker.size}<extra></extra>\", \"legendgroup\": \"Setosa\", \"marker\": {\"color\": \"#636efa\", \"opacity\": 0.7, \"size\": [1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.4, 1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1.5, 1.7, 1.5, 1.0, 1.7, 1.9, 1.6, 1.6, 1.5, 1.4, 1.6, 1.6, 1.5, 1.5, 1.4, 1.5, 1.2, 1.3, 1.4, 1.3, 1.5, 1.3, 1.3, 1.3, 1.6, 1.9, 1.4, 1.6, 1.4, 1.5, 1.4], \"sizemode\": \"area\", \"sizeref\": 0.01725, \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"Setosa\", \"scene\": \"scene\", \"showlegend\": true, \"type\": \"scatter3d\", \"x\": [5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5.0, 5.0, 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5.0, 5.5, 4.9, 4.4, 5.1, 5.0, 4.5, 4.4, 5.0, 5.1, 4.8, 5.1, 4.6, 5.3, 5.0], \"y\": [3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.0, 3.0, 4.0, 4.4, 3.9, 3.5, 3.8, 3.8, 3.4, 3.7, 3.6, 3.3, 3.4, 3.0, 3.4, 3.5, 3.4, 3.2, 3.1, 3.4, 4.1, 4.2, 3.1, 3.2, 3.5, 3.6, 3.0, 3.4, 3.5, 2.3, 3.2, 3.5, 3.8, 3.0, 3.8, 3.2, 3.7, 3.3], \"z\": [0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.2, 0.2, 0.2, 0.1, 0.2, 0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2]}, {\"hovertemplate\": \"variety=Versicolor<br>sepal.length=%{x}<br>sepal.width=%{y}<br>petal.width=%{z}<br>petal.length=%{marker.size}<extra></extra>\", \"legendgroup\": \"Versicolor\", \"marker\": {\"color\": \"#EF553B\", \"opacity\": 0.7, \"size\": [4.7, 4.5, 4.9, 4.0, 4.6, 4.5, 4.7, 3.3, 4.6, 3.9, 3.5, 4.2, 4.0, 4.7, 3.6, 4.4, 4.5, 4.1, 4.5, 3.9, 4.8, 4.0, 4.9, 4.7, 4.3, 4.4, 4.8, 5.0, 4.5, 3.5, 3.8, 3.7, 3.9, 5.1, 4.5, 4.5, 4.7, 4.4, 4.1, 4.0, 4.4, 4.6, 4.0, 3.3, 4.2, 4.2, 4.2, 4.3, 3.0, 4.1], \"sizemode\": \"area\", \"sizeref\": 0.01725, \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"Versicolor\", \"scene\": \"scene\", \"showlegend\": true, \"type\": \"scatter3d\", \"x\": [7.0, 6.4, 6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5.0, 5.9, 6.0, 6.1, 5.6, 6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7, 6.0, 5.7, 5.5, 5.5, 5.8, 6.0, 5.4, 6.0, 6.7, 6.3, 5.6, 5.5, 5.5, 6.1, 5.8, 5.0, 5.6, 5.7, 5.7, 6.2, 5.1, 5.7], \"y\": [3.2, 3.2, 3.1, 2.3, 2.8, 2.8, 3.3, 2.4, 2.9, 2.7, 2.0, 3.0, 2.2, 2.9, 2.9, 3.1, 3.0, 2.7, 2.2, 2.5, 3.2, 2.8, 2.5, 2.8, 2.9, 3.0, 2.8, 3.0, 2.9, 2.6, 2.4, 2.4, 2.7, 2.7, 3.0, 3.4, 3.1, 2.3, 3.0, 2.5, 2.6, 3.0, 2.6, 2.3, 2.7, 3.0, 2.9, 2.9, 2.5, 2.8], \"z\": [1.4, 1.5, 1.5, 1.3, 1.5, 1.3, 1.6, 1.0, 1.3, 1.4, 1.0, 1.5, 1.0, 1.4, 1.3, 1.4, 1.5, 1.0, 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7, 1.5, 1.0, 1.1, 1.0, 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2, 1.4, 1.2, 1.0, 1.3, 1.2, 1.3, 1.3, 1.1, 1.3]}, {\"hovertemplate\": \"variety=Virginica<br>sepal.length=%{x}<br>sepal.width=%{y}<br>petal.width=%{z}<br>petal.length=%{marker.size}<extra></extra>\", \"legendgroup\": \"Virginica\", \"marker\": {\"color\": \"#00cc96\", \"opacity\": 0.7, \"size\": [6.0, 5.1, 5.9, 5.6, 5.8, 6.6, 4.5, 6.3, 5.8, 6.1, 5.1, 5.3, 5.5, 5.0, 5.1, 5.3, 5.5, 6.7, 6.9, 5.0, 5.7, 4.9, 6.7, 4.9, 5.7, 6.0, 4.8, 4.9, 5.6, 5.8, 6.1, 6.4, 5.6, 5.1, 5.6, 6.1, 5.6, 5.5, 4.8, 5.4, 5.6, 5.1, 5.1, 5.9, 5.7, 5.2, 5.0, 5.2, 5.4, 5.1], \"sizemode\": \"area\", \"sizeref\": 0.01725, \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"Virginica\", \"scene\": \"scene\", \"showlegend\": true, \"type\": \"scatter3d\", \"x\": [6.3, 5.8, 7.1, 6.3, 6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, 7.7, 7.7, 6.0, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6.0, 6.9, 6.7, 6.9, 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9], \"y\": [3.3, 2.7, 3.0, 2.9, 3.0, 3.0, 2.5, 2.9, 2.5, 3.6, 3.2, 2.7, 3.0, 2.5, 2.8, 3.2, 3.0, 3.8, 2.6, 2.2, 3.2, 2.8, 2.8, 2.7, 3.3, 3.2, 2.8, 3.0, 2.8, 3.0, 2.8, 3.8, 2.8, 2.8, 2.6, 3.0, 3.4, 3.1, 3.0, 3.1, 3.1, 3.1, 2.7, 3.2, 3.3, 3.0, 2.5, 3.0, 3.4, 3.0], \"z\": [2.5, 1.9, 2.1, 1.8, 2.2, 2.1, 1.7, 1.8, 1.8, 2.5, 2.0, 1.9, 2.1, 2.0, 2.4, 2.3, 1.8, 2.2, 2.3, 1.5, 2.3, 2.0, 2.0, 1.8, 2.1, 1.8, 1.8, 1.8, 2.1, 1.6, 1.9, 2.0, 2.2, 1.5, 1.4, 2.3, 2.4, 1.8, 1.8, 2.1, 2.4, 2.3, 1.9, 2.3, 2.5, 2.3, 1.9, 2.0, 2.3, 1.8]}],                        {\"legend\": {\"itemsizing\": \"constant\", \"title\": {\"text\": \"variety\"}, \"tracegroupgap\": 0}, \"margin\": {\"b\": 0, \"l\": 0, \"r\": 0, \"t\": 0}, \"scene\": {\"domain\": {\"x\": [0.0, 1.0], \"y\": [0.0, 1.0]}, \"xaxis\": {\"title\": {\"text\": \"sepal.length\"}}, \"yaxis\": {\"title\": {\"text\": \"sepal.width\"}}, \"zaxis\": {\"title\": {\"text\": \"petal.width\"}}}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "\n",
    "\n",
    "fig = px.scatter_3d(iris[[\"sepal.length\",\"sepal.width\",\"petal.length\",\"petal.width\",\"variety\"]],\n",
    "                    x = 'sepal.length',\n",
    "                    y = 'sepal.width',\n",
    "                    z = 'petal.width',\n",
    "                    size = 'petal.length',\n",
    "                    color = 'variety',\n",
    "                    opacity = 0.7)\n",
    "\n",
    "fig.update_layout(margin = dict(l=0, r=0, b=0, t=0))\n",
    "\n",
    "\n",
    "HTML(plotly.offline.plot(fig, filename='5d_iris_scatter.html',include_plotlyjs='cdn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>                        <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"8be0123c-ecb1-4a95-9d69-7f8c73e8c1bc\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8be0123c-ecb1-4a95-9d69-7f8c73e8c1bc\")) {                    Plotly.newPlot(                        \"8be0123c-ecb1-4a95-9d69-7f8c73e8c1bc\",                        [{\"dimensions\": [{\"axis\": {\"matches\": true}, \"label\": \"sepal.width\", \"values\": [3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.0, 3.0, 4.0, 4.4, 3.9, 3.5, 3.8, 3.8, 3.4, 3.7, 3.6, 3.3, 3.4, 3.0, 3.4, 3.5, 3.4, 3.2, 3.1, 3.4, 4.1, 4.2, 3.1, 3.2, 3.5, 3.6, 3.0, 3.4, 3.5, 2.3, 3.2, 3.5, 3.8, 3.0, 3.8, 3.2, 3.7, 3.3]}, {\"axis\": {\"matches\": true}, \"label\": \"sepal.length\", \"values\": [5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5.0, 5.0, 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5.0, 5.5, 4.9, 4.4, 5.1, 5.0, 4.5, 4.4, 5.0, 5.1, 4.8, 5.1, 4.6, 5.3, 5.0]}, {\"axis\": {\"matches\": true}, \"label\": \"petal.width\", \"values\": [0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.2, 0.2, 0.2, 0.1, 0.2, 0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2]}, {\"axis\": {\"matches\": true}, \"label\": \"petal.length\", \"values\": [1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.4, 1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1.5, 1.7, 1.5, 1.0, 1.7, 1.9, 1.6, 1.6, 1.5, 1.4, 1.6, 1.6, 1.5, 1.5, 1.4, 1.5, 1.2, 1.3, 1.4, 1.3, 1.5, 1.3, 1.3, 1.3, 1.6, 1.9, 1.4, 1.6, 1.4, 1.5, 1.4]}], \"hovertemplate\": \"variety=Setosa<br>%{xaxis.title.text}=%{x}<br>%{yaxis.title.text}=%{y}<extra></extra>\", \"legendgroup\": \"Setosa\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"name\": \"Setosa\", \"showlegend\": true, \"type\": \"splom\"}, {\"dimensions\": [{\"axis\": {\"matches\": true}, \"label\": \"sepal.width\", \"values\": [3.2, 3.2, 3.1, 2.3, 2.8, 2.8, 3.3, 2.4, 2.9, 2.7, 2.0, 3.0, 2.2, 2.9, 2.9, 3.1, 3.0, 2.7, 2.2, 2.5, 3.2, 2.8, 2.5, 2.8, 2.9, 3.0, 2.8, 3.0, 2.9, 2.6, 2.4, 2.4, 2.7, 2.7, 3.0, 3.4, 3.1, 2.3, 3.0, 2.5, 2.6, 3.0, 2.6, 2.3, 2.7, 3.0, 2.9, 2.9, 2.5, 2.8]}, {\"axis\": {\"matches\": true}, \"label\": \"sepal.length\", \"values\": [7.0, 6.4, 6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5.0, 5.9, 6.0, 6.1, 5.6, 6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7, 6.0, 5.7, 5.5, 5.5, 5.8, 6.0, 5.4, 6.0, 6.7, 6.3, 5.6, 5.5, 5.5, 6.1, 5.8, 5.0, 5.6, 5.7, 5.7, 6.2, 5.1, 5.7]}, {\"axis\": {\"matches\": true}, \"label\": \"petal.width\", \"values\": [1.4, 1.5, 1.5, 1.3, 1.5, 1.3, 1.6, 1.0, 1.3, 1.4, 1.0, 1.5, 1.0, 1.4, 1.3, 1.4, 1.5, 1.0, 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7, 1.5, 1.0, 1.1, 1.0, 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2, 1.4, 1.2, 1.0, 1.3, 1.2, 1.3, 1.3, 1.1, 1.3]}, {\"axis\": {\"matches\": true}, \"label\": \"petal.length\", \"values\": [4.7, 4.5, 4.9, 4.0, 4.6, 4.5, 4.7, 3.3, 4.6, 3.9, 3.5, 4.2, 4.0, 4.7, 3.6, 4.4, 4.5, 4.1, 4.5, 3.9, 4.8, 4.0, 4.9, 4.7, 4.3, 4.4, 4.8, 5.0, 4.5, 3.5, 3.8, 3.7, 3.9, 5.1, 4.5, 4.5, 4.7, 4.4, 4.1, 4.0, 4.4, 4.6, 4.0, 3.3, 4.2, 4.2, 4.2, 4.3, 3.0, 4.1]}], \"hovertemplate\": \"variety=Versicolor<br>%{xaxis.title.text}=%{x}<br>%{yaxis.title.text}=%{y}<extra></extra>\", \"legendgroup\": \"Versicolor\", \"marker\": {\"color\": \"#EF553B\", \"symbol\": \"circle\"}, \"name\": \"Versicolor\", \"showlegend\": true, \"type\": \"splom\"}, {\"dimensions\": [{\"axis\": {\"matches\": true}, \"label\": \"sepal.width\", \"values\": [3.3, 2.7, 3.0, 2.9, 3.0, 3.0, 2.5, 2.9, 2.5, 3.6, 3.2, 2.7, 3.0, 2.5, 2.8, 3.2, 3.0, 3.8, 2.6, 2.2, 3.2, 2.8, 2.8, 2.7, 3.3, 3.2, 2.8, 3.0, 2.8, 3.0, 2.8, 3.8, 2.8, 2.8, 2.6, 3.0, 3.4, 3.1, 3.0, 3.1, 3.1, 3.1, 2.7, 3.2, 3.3, 3.0, 2.5, 3.0, 3.4, 3.0]}, {\"axis\": {\"matches\": true}, \"label\": \"sepal.length\", \"values\": [6.3, 5.8, 7.1, 6.3, 6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, 7.7, 7.7, 6.0, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6.0, 6.9, 6.7, 6.9, 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9]}, {\"axis\": {\"matches\": true}, \"label\": \"petal.width\", \"values\": [2.5, 1.9, 2.1, 1.8, 2.2, 2.1, 1.7, 1.8, 1.8, 2.5, 2.0, 1.9, 2.1, 2.0, 2.4, 2.3, 1.8, 2.2, 2.3, 1.5, 2.3, 2.0, 2.0, 1.8, 2.1, 1.8, 1.8, 1.8, 2.1, 1.6, 1.9, 2.0, 2.2, 1.5, 1.4, 2.3, 2.4, 1.8, 1.8, 2.1, 2.4, 2.3, 1.9, 2.3, 2.5, 2.3, 1.9, 2.0, 2.3, 1.8]}, {\"axis\": {\"matches\": true}, \"label\": \"petal.length\", \"values\": [6.0, 5.1, 5.9, 5.6, 5.8, 6.6, 4.5, 6.3, 5.8, 6.1, 5.1, 5.3, 5.5, 5.0, 5.1, 5.3, 5.5, 6.7, 6.9, 5.0, 5.7, 4.9, 6.7, 4.9, 5.7, 6.0, 4.8, 4.9, 5.6, 5.8, 6.1, 6.4, 5.6, 5.1, 5.6, 6.1, 5.6, 5.5, 4.8, 5.4, 5.6, 5.1, 5.1, 5.9, 5.7, 5.2, 5.0, 5.2, 5.4, 5.1]}], \"hovertemplate\": \"variety=Virginica<br>%{xaxis.title.text}=%{x}<br>%{yaxis.title.text}=%{y}<extra></extra>\", \"legendgroup\": \"Virginica\", \"marker\": {\"color\": \"#00cc96\", \"symbol\": \"circle\"}, \"name\": \"Virginica\", \"showlegend\": true, \"type\": \"splom\"}],                        {\"dragmode\": \"select\", \"legend\": {\"title\": {\"text\": \"variety\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "fig = px.scatter_matrix(iris, dimensions=[\"sepal.width\", \"sepal.length\", \"petal.width\", \"petal.length\"],color=\"variety\")\n",
    "HTML(plotly.offline.plot(fig, filename='5d_scatter_matrix.html',include_plotlyjs='cdn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input columns all:  torch.Size([150, 3]) torch.float32\nInput columns:  torch.Size([150, 2]) torch.float32\nOutput columns:  torch.Size([150]) torch.int8\n"
     ]
    }
   ],
   "source": [
    "selected_features = ['petal.length', 'petal.width']\n",
    "\n",
    "input_columns_all = torch.from_numpy(iris[list(iris.columns)[:-2]].to_numpy()).type(torch.float32)\n",
    "input_columns = torch.from_numpy(iris[selected_features].to_numpy()).type(torch.float32)\n",
    "output_columns = torch.tensor(iris['variety'].astype('category').cat.codes)\n",
    "\n",
    "print(\"Input columns all: \", input_columns_all.shape, input_columns_all.dtype)\n",
    "print(\"Input columns: \", input_columns.shape, input_columns.dtype)\n",
    "print(\"Output columns: \", output_columns.shape, output_columns.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.utils.data.TensorDataset(input_columns, output_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.1\n",
    "rows = list(input_columns.shape)[0]\n",
    "test_split = int(rows*split)\n",
    "val_split = int(rows*split*2)\n",
    "train_split = rows - val_split - test_split\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(data, [train_split, val_split, test_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, 16, shuffle = True) #batch size = 16\n",
    "val_loader = torch.utils.data.DataLoader(val_set) #batch size = 1\n",
    "test_loader = torch.utils.data.DataLoader(test_set) #batch size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dimension, output_dimension):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dimension, output_dimension)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, targets.long())\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, targets.long())\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        accuracy = torch.tensor(torch.sum(pred==targets).item()/len(pred))\n",
    "        return [loss.detach(), accuracy.detach()] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "model = LogisticRegression(len(selected_features), len(species))\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, val_loader, epochs, lr, criterion_function = torch.nn.functional.cross_entropy, optimizer_function = torch.optim.Adam):\n",
    "    history = {\"loss\" : [], \"accuracy\" : []}\n",
    "    optimizer = optimizer_function(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch \", epoch)\n",
    "        #Train\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        #Validate\n",
    "        for batch in val_loader:\n",
    "            loss, accuracy = evaluate(model, val_loader)\n",
    "        print(\"loss: \", loss.item(), \"accuracy: \", accuracy.item(), \"\\n\")\n",
    "        history[\"loss\"].append(loss.item())\n",
    "        history[\"accuracy\"].append(accuracy.item())\n",
    "         \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    outputs = [model.validation_step(batch) for batch in loader]\n",
    "    outputs = torch.tensor(outputs).T\n",
    "    loss, accuracy = torch.mean(outputs, dim=1)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch  0\n",
      "loss:  1.6985193490982056 accuracy:  0.30000001192092896 \n",
      "\n",
      "Epoch  1\n",
      "loss:  1.4178080558776855 accuracy:  0.30000001192092896 \n",
      "\n",
      "Epoch  2\n",
      "loss:  1.2302438020706177 accuracy:  0.30000001192092896 \n",
      "\n",
      "Epoch  3\n",
      "loss:  1.1358810663223267 accuracy:  0.30000001192092896 \n",
      "\n",
      "Epoch  4\n",
      "loss:  1.101354718208313 accuracy:  0.30000001192092896 \n",
      "\n",
      "Epoch  5\n",
      "loss:  1.0809509754180908 accuracy:  0.30000001192092896 \n",
      "\n",
      "Epoch  6\n",
      "loss:  1.0579463243484497 accuracy:  0.30000001192092896 \n",
      "\n",
      "Epoch  7\n",
      "loss:  1.0323728322982788 accuracy:  0.30000001192092896 \n",
      "\n",
      "Epoch  8\n",
      "loss:  1.0059645175933838 accuracy:  0.30000001192092896 \n",
      "\n",
      "Epoch  9\n",
      "loss:  0.9818710088729858 accuracy:  0.30000001192092896 \n",
      "\n",
      "Epoch  10\n",
      "loss:  0.9644540548324585 accuracy:  0.5333333611488342 \n",
      "\n",
      "Epoch  11\n",
      "loss:  0.9398399591445923 accuracy:  0.3333333432674408 \n",
      "\n",
      "Epoch  12\n",
      "loss:  0.915465772151947 accuracy:  0.30000001192092896 \n",
      "\n",
      "Epoch  13\n",
      "loss:  0.8922751545906067 accuracy:  0.30000001192092896 \n",
      "\n",
      "Epoch  14\n",
      "loss:  0.8723837733268738 accuracy:  0.5333333611488342 \n",
      "\n",
      "Epoch  15\n",
      "loss:  0.8529859781265259 accuracy:  0.6333333253860474 \n",
      "\n",
      "Epoch  16\n",
      "loss:  0.8332421183586121 accuracy:  0.6666666865348816 \n",
      "\n",
      "Epoch  17\n",
      "loss:  0.8193958401679993 accuracy:  0.699999988079071 \n",
      "\n",
      "Epoch  18\n",
      "loss:  0.8039640784263611 accuracy:  0.699999988079071 \n",
      "\n",
      "Epoch  19\n",
      "loss:  0.7884728908538818 accuracy:  0.7333333492279053 \n",
      "\n",
      "Epoch  20\n",
      "loss:  0.7722324132919312 accuracy:  0.7333333492279053 \n",
      "\n",
      "Epoch  21\n",
      "loss:  0.7557240724563599 accuracy:  0.7333333492279053 \n",
      "\n",
      "Epoch  22\n",
      "loss:  0.7399097084999084 accuracy:  0.7333333492279053 \n",
      "\n",
      "Epoch  23\n",
      "loss:  0.7267166376113892 accuracy:  0.7333333492279053 \n",
      "\n",
      "Epoch  24\n",
      "loss:  0.7123829126358032 accuracy:  0.699999988079071 \n",
      "\n",
      "Epoch  25\n",
      "loss:  0.6996530294418335 accuracy:  0.7333333492279053 \n",
      "\n",
      "Epoch  26\n",
      "loss:  0.6895722150802612 accuracy:  0.8333333134651184 \n",
      "\n",
      "Epoch  27\n",
      "loss:  0.6813505291938782 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  28\n",
      "loss:  0.6683018803596497 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  29\n",
      "loss:  0.6538861393928528 accuracy:  0.7333333492279053 \n",
      "\n",
      "Epoch  30\n",
      "loss:  0.6450960636138916 accuracy:  0.7333333492279053 \n",
      "\n",
      "Epoch  31\n",
      "loss:  0.6354535818099976 accuracy:  0.7333333492279053 \n",
      "\n",
      "Epoch  32\n",
      "loss:  0.6249321699142456 accuracy:  0.7333333492279053 \n",
      "\n",
      "Epoch  33\n",
      "loss:  0.6154871582984924 accuracy:  0.8333333134651184 \n",
      "\n",
      "Epoch  34\n",
      "loss:  0.6057191491127014 accuracy:  0.8333333134651184 \n",
      "\n",
      "Epoch  35\n",
      "loss:  0.5977340340614319 accuracy:  0.800000011920929 \n",
      "\n",
      "Epoch  36\n",
      "loss:  0.5890392661094666 accuracy:  0.8333333134651184 \n",
      "\n",
      "Epoch  37\n",
      "loss:  0.5804833173751831 accuracy:  0.7666666507720947 \n",
      "\n",
      "Epoch  38\n",
      "loss:  0.5775497555732727 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  39\n",
      "loss:  0.5702192783355713 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  40\n",
      "loss:  0.5621476769447327 accuracy:  0.7333333492279053 \n",
      "\n",
      "Epoch  41\n",
      "loss:  0.5548458099365234 accuracy:  0.8333333134651184 \n",
      "\n",
      "Epoch  42\n",
      "loss:  0.5479496121406555 accuracy:  0.8333333134651184 \n",
      "\n",
      "Epoch  43\n",
      "loss:  0.5421233773231506 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  44\n",
      "loss:  0.537203848361969 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  45\n",
      "loss:  0.5295308828353882 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  46\n",
      "loss:  0.5238269567489624 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  47\n",
      "loss:  0.5189450979232788 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  48\n",
      "loss:  0.5128089189529419 accuracy:  0.8333333134651184 \n",
      "\n",
      "Epoch  49\n",
      "loss:  0.5078200101852417 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  50\n",
      "loss:  0.5020116567611694 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  51\n",
      "loss:  0.4970574676990509 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  52\n",
      "loss:  0.4924750328063965 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  53\n",
      "loss:  0.4871114194393158 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  54\n",
      "loss:  0.4830981194972992 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  55\n",
      "loss:  0.4792887270450592 accuracy:  0.8999999761581421 \n",
      "\n",
      "Epoch  56\n",
      "loss:  0.474981427192688 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  57\n",
      "loss:  0.47078508138656616 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  58\n",
      "loss:  0.46801745891571045 accuracy:  0.8333333134651184 \n",
      "\n",
      "Epoch  59\n",
      "loss:  0.46295222640037537 accuracy:  0.8333333134651184 \n",
      "\n",
      "Epoch  60\n",
      "loss:  0.45820173621177673 accuracy:  0.8333333134651184 \n",
      "\n",
      "Epoch  61\n",
      "loss:  0.45413222908973694 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  62\n",
      "loss:  0.45128098130226135 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  63\n",
      "loss:  0.4485507607460022 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  64\n",
      "loss:  0.4438554048538208 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  65\n",
      "loss:  0.43998003005981445 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  66\n",
      "loss:  0.43656718730926514 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  67\n",
      "loss:  0.4330132305622101 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  68\n",
      "loss:  0.4296515882015228 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  69\n",
      "loss:  0.425968736410141 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  70\n",
      "loss:  0.42295199632644653 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  71\n",
      "loss:  0.42113175988197327 accuracy:  0.8333333134651184 \n",
      "\n",
      "Epoch  72\n",
      "loss:  0.41844046115875244 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  73\n",
      "loss:  0.4149874448776245 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  74\n",
      "loss:  0.4127081632614136 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  75\n",
      "loss:  0.40915998816490173 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  76\n",
      "loss:  0.4061294496059418 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  77\n",
      "loss:  0.40317440032958984 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  78\n",
      "loss:  0.40117523074150085 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  79\n",
      "loss:  0.3981017768383026 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  80\n",
      "loss:  0.3956863284111023 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  81\n",
      "loss:  0.3930688500404358 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  82\n",
      "loss:  0.39022865891456604 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  83\n",
      "loss:  0.38820183277130127 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  84\n",
      "loss:  0.3854881823062897 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  85\n",
      "loss:  0.3841487169265747 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  86\n",
      "loss:  0.382907509803772 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  87\n",
      "loss:  0.379690945148468 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  88\n",
      "loss:  0.37602895498275757 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  89\n",
      "loss:  0.3741013705730438 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  90\n",
      "loss:  0.37442705035209656 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  91\n",
      "loss:  0.3709593415260315 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  92\n",
      "loss:  0.36855584383010864 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  93\n",
      "loss:  0.3653481900691986 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  94\n",
      "loss:  0.3631134629249573 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  95\n",
      "loss:  0.3611810505390167 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  96\n",
      "loss:  0.3589538633823395 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  97\n",
      "loss:  0.35742446780204773 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  98\n",
      "loss:  0.35565245151519775 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  99\n",
      "loss:  0.3538565933704376 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  100\n",
      "loss:  0.351683109998703 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  101\n",
      "loss:  0.3492344617843628 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  102\n",
      "loss:  0.3472057282924652 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  103\n",
      "loss:  0.34536632895469666 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  104\n",
      "loss:  0.3434551954269409 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  105\n",
      "loss:  0.3420809507369995 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  106\n",
      "loss:  0.3430423140525818 accuracy:  0.8666666746139526 \n",
      "\n",
      "Epoch  107\n",
      "loss:  0.33915287256240845 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  108\n",
      "loss:  0.3370930552482605 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  109\n",
      "loss:  0.3354191184043884 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  110\n",
      "loss:  0.3332492709159851 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  111\n",
      "loss:  0.3317165970802307 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  112\n",
      "loss:  0.33092352747917175 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  113\n",
      "loss:  0.32864391803741455 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  114\n",
      "loss:  0.32773539423942566 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  115\n",
      "loss:  0.3265474736690521 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  116\n",
      "loss:  0.32642489671707153 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  117\n",
      "loss:  0.3233598470687866 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  118\n",
      "loss:  0.32036298513412476 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  119\n",
      "loss:  0.3187800347805023 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  120\n",
      "loss:  0.31718626618385315 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  121\n",
      "loss:  0.317478746175766 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  122\n",
      "loss:  0.31579554080963135 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  123\n",
      "loss:  0.3135000169277191 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  124\n",
      "loss:  0.3114442527294159 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  125\n",
      "loss:  0.3130922019481659 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  126\n",
      "loss:  0.3087867498397827 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  127\n",
      "loss:  0.30742761492729187 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  128\n",
      "loss:  0.3068270683288574 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  129\n",
      "loss:  0.3049343228340149 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  130\n",
      "loss:  0.30421462655067444 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  131\n",
      "loss:  0.3043287396430969 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  132\n",
      "loss:  0.3016758859157562 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  133\n",
      "loss:  0.2997283935546875 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  134\n",
      "loss:  0.2985145151615143 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  135\n",
      "loss:  0.29693445563316345 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  136\n",
      "loss:  0.2954198718070984 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  137\n",
      "loss:  0.2956731617450714 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  138\n",
      "loss:  0.29460495710372925 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  139\n",
      "loss:  0.2927214503288269 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  140\n",
      "loss:  0.2927578091621399 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  141\n",
      "loss:  0.2918640077114105 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  142\n",
      "loss:  0.291454941034317 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  143\n",
      "loss:  0.28902530670166016 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  144\n",
      "loss:  0.2870039939880371 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  145\n",
      "loss:  0.2854677736759186 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  146\n",
      "loss:  0.28698432445526123 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  147\n",
      "loss:  0.2858055830001831 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  148\n",
      "loss:  0.2819862961769104 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  149\n",
      "loss:  0.28108084201812744 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  150\n",
      "loss:  0.28108102083206177 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  151\n",
      "loss:  0.28461065888404846 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  152\n",
      "loss:  0.2775873839855194 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  153\n",
      "loss:  0.2768307030200958 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  154\n",
      "loss:  0.2758568823337555 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  155\n",
      "loss:  0.2741895318031311 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  156\n",
      "loss:  0.2727888524532318 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  157\n",
      "loss:  0.27288466691970825 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  158\n",
      "loss:  0.2740163505077362 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  159\n",
      "loss:  0.2733244001865387 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  160\n",
      "loss:  0.26958757638931274 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  161\n",
      "loss:  0.26799142360687256 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  162\n",
      "loss:  0.27137690782546997 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  163\n",
      "loss:  0.26857465505599976 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  164\n",
      "loss:  0.2663209140300751 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  165\n",
      "loss:  0.26403337717056274 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  166\n",
      "loss:  0.26394274830818176 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  167\n",
      "loss:  0.2638937830924988 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  168\n",
      "loss:  0.26268014311790466 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  169\n",
      "loss:  0.26225292682647705 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  170\n",
      "loss:  0.2609357535839081 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  171\n",
      "loss:  0.26137638092041016 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  172\n",
      "loss:  0.26007080078125 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  173\n",
      "loss:  0.2578636407852173 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  174\n",
      "loss:  0.25585415959358215 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  175\n",
      "loss:  0.25782081484794617 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  176\n",
      "loss:  0.2552277445793152 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  177\n",
      "loss:  0.25934898853302 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  178\n",
      "loss:  0.2542091906070709 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  179\n",
      "loss:  0.25050342082977295 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  180\n",
      "loss:  0.2490861415863037 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  181\n",
      "loss:  0.2502380907535553 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  182\n",
      "loss:  0.2505325675010681 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  183\n",
      "loss:  0.2502928674221039 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  184\n",
      "loss:  0.24680322408676147 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  185\n",
      "loss:  0.24675092101097107 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  186\n",
      "loss:  0.24707089364528656 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  187\n",
      "loss:  0.2440774291753769 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  188\n",
      "loss:  0.24538494646549225 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  189\n",
      "loss:  0.24639376997947693 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  190\n",
      "loss:  0.2441643327474594 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  191\n",
      "loss:  0.24269956350326538 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  192\n",
      "loss:  0.24213990569114685 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  193\n",
      "loss:  0.2417818158864975 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  194\n",
      "loss:  0.24277567863464355 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  195\n",
      "loss:  0.23846203088760376 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  196\n",
      "loss:  0.24372181296348572 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  197\n",
      "loss:  0.23902250826358795 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  198\n",
      "loss:  0.23744064569473267 accuracy:  0.9666666388511658 \n",
      "\n",
      "Epoch  199\n",
      "loss:  0.2333313524723053 accuracy:  0.9666666388511658 \n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'loss': [1.6985193490982056,\n",
       "  1.4178080558776855,\n",
       "  1.2302438020706177,\n",
       "  1.1358810663223267,\n",
       "  1.101354718208313,\n",
       "  1.0809509754180908,\n",
       "  1.0579463243484497,\n",
       "  1.0323728322982788,\n",
       "  1.0059645175933838,\n",
       "  0.9818710088729858,\n",
       "  0.9644540548324585,\n",
       "  0.9398399591445923,\n",
       "  0.915465772151947,\n",
       "  0.8922751545906067,\n",
       "  0.8723837733268738,\n",
       "  0.8529859781265259,\n",
       "  0.8332421183586121,\n",
       "  0.8193958401679993,\n",
       "  0.8039640784263611,\n",
       "  0.7884728908538818,\n",
       "  0.7722324132919312,\n",
       "  0.7557240724563599,\n",
       "  0.7399097084999084,\n",
       "  0.7267166376113892,\n",
       "  0.7123829126358032,\n",
       "  0.6996530294418335,\n",
       "  0.6895722150802612,\n",
       "  0.6813505291938782,\n",
       "  0.6683018803596497,\n",
       "  0.6538861393928528,\n",
       "  0.6450960636138916,\n",
       "  0.6354535818099976,\n",
       "  0.6249321699142456,\n",
       "  0.6154871582984924,\n",
       "  0.6057191491127014,\n",
       "  0.5977340340614319,\n",
       "  0.5890392661094666,\n",
       "  0.5804833173751831,\n",
       "  0.5775497555732727,\n",
       "  0.5702192783355713,\n",
       "  0.5621476769447327,\n",
       "  0.5548458099365234,\n",
       "  0.5479496121406555,\n",
       "  0.5421233773231506,\n",
       "  0.537203848361969,\n",
       "  0.5295308828353882,\n",
       "  0.5238269567489624,\n",
       "  0.5189450979232788,\n",
       "  0.5128089189529419,\n",
       "  0.5078200101852417,\n",
       "  0.5020116567611694,\n",
       "  0.4970574676990509,\n",
       "  0.4924750328063965,\n",
       "  0.4871114194393158,\n",
       "  0.4830981194972992,\n",
       "  0.4792887270450592,\n",
       "  0.474981427192688,\n",
       "  0.47078508138656616,\n",
       "  0.46801745891571045,\n",
       "  0.46295222640037537,\n",
       "  0.45820173621177673,\n",
       "  0.45413222908973694,\n",
       "  0.45128098130226135,\n",
       "  0.4485507607460022,\n",
       "  0.4438554048538208,\n",
       "  0.43998003005981445,\n",
       "  0.43656718730926514,\n",
       "  0.4330132305622101,\n",
       "  0.4296515882015228,\n",
       "  0.425968736410141,\n",
       "  0.42295199632644653,\n",
       "  0.42113175988197327,\n",
       "  0.41844046115875244,\n",
       "  0.4149874448776245,\n",
       "  0.4127081632614136,\n",
       "  0.40915998816490173,\n",
       "  0.4061294496059418,\n",
       "  0.40317440032958984,\n",
       "  0.40117523074150085,\n",
       "  0.3981017768383026,\n",
       "  0.3956863284111023,\n",
       "  0.3930688500404358,\n",
       "  0.39022865891456604,\n",
       "  0.38820183277130127,\n",
       "  0.3854881823062897,\n",
       "  0.3841487169265747,\n",
       "  0.382907509803772,\n",
       "  0.379690945148468,\n",
       "  0.37602895498275757,\n",
       "  0.3741013705730438,\n",
       "  0.37442705035209656,\n",
       "  0.3709593415260315,\n",
       "  0.36855584383010864,\n",
       "  0.3653481900691986,\n",
       "  0.3631134629249573,\n",
       "  0.3611810505390167,\n",
       "  0.3589538633823395,\n",
       "  0.35742446780204773,\n",
       "  0.35565245151519775,\n",
       "  0.3538565933704376,\n",
       "  0.351683109998703,\n",
       "  0.3492344617843628,\n",
       "  0.3472057282924652,\n",
       "  0.34536632895469666,\n",
       "  0.3434551954269409,\n",
       "  0.3420809507369995,\n",
       "  0.3430423140525818,\n",
       "  0.33915287256240845,\n",
       "  0.3370930552482605,\n",
       "  0.3354191184043884,\n",
       "  0.3332492709159851,\n",
       "  0.3317165970802307,\n",
       "  0.33092352747917175,\n",
       "  0.32864391803741455,\n",
       "  0.32773539423942566,\n",
       "  0.3265474736690521,\n",
       "  0.32642489671707153,\n",
       "  0.3233598470687866,\n",
       "  0.32036298513412476,\n",
       "  0.3187800347805023,\n",
       "  0.31718626618385315,\n",
       "  0.317478746175766,\n",
       "  0.31579554080963135,\n",
       "  0.3135000169277191,\n",
       "  0.3114442527294159,\n",
       "  0.3130922019481659,\n",
       "  0.3087867498397827,\n",
       "  0.30742761492729187,\n",
       "  0.3068270683288574,\n",
       "  0.3049343228340149,\n",
       "  0.30421462655067444,\n",
       "  0.3043287396430969,\n",
       "  0.3016758859157562,\n",
       "  0.2997283935546875,\n",
       "  0.2985145151615143,\n",
       "  0.29693445563316345,\n",
       "  0.2954198718070984,\n",
       "  0.2956731617450714,\n",
       "  0.29460495710372925,\n",
       "  0.2927214503288269,\n",
       "  0.2927578091621399,\n",
       "  0.2918640077114105,\n",
       "  0.291454941034317,\n",
       "  0.28902530670166016,\n",
       "  0.2870039939880371,\n",
       "  0.2854677736759186,\n",
       "  0.28698432445526123,\n",
       "  0.2858055830001831,\n",
       "  0.2819862961769104,\n",
       "  0.28108084201812744,\n",
       "  0.28108102083206177,\n",
       "  0.28461065888404846,\n",
       "  0.2775873839855194,\n",
       "  0.2768307030200958,\n",
       "  0.2758568823337555,\n",
       "  0.2741895318031311,\n",
       "  0.2727888524532318,\n",
       "  0.27288466691970825,\n",
       "  0.2740163505077362,\n",
       "  0.2733244001865387,\n",
       "  0.26958757638931274,\n",
       "  0.26799142360687256,\n",
       "  0.27137690782546997,\n",
       "  0.26857465505599976,\n",
       "  0.2663209140300751,\n",
       "  0.26403337717056274,\n",
       "  0.26394274830818176,\n",
       "  0.2638937830924988,\n",
       "  0.26268014311790466,\n",
       "  0.26225292682647705,\n",
       "  0.2609357535839081,\n",
       "  0.26137638092041016,\n",
       "  0.26007080078125,\n",
       "  0.2578636407852173,\n",
       "  0.25585415959358215,\n",
       "  0.25782081484794617,\n",
       "  0.2552277445793152,\n",
       "  0.25934898853302,\n",
       "  0.2542091906070709,\n",
       "  0.25050342082977295,\n",
       "  0.2490861415863037,\n",
       "  0.2502380907535553,\n",
       "  0.2505325675010681,\n",
       "  0.2502928674221039,\n",
       "  0.24680322408676147,\n",
       "  0.24675092101097107,\n",
       "  0.24707089364528656,\n",
       "  0.2440774291753769,\n",
       "  0.24538494646549225,\n",
       "  0.24639376997947693,\n",
       "  0.2441643327474594,\n",
       "  0.24269956350326538,\n",
       "  0.24213990569114685,\n",
       "  0.2417818158864975,\n",
       "  0.24277567863464355,\n",
       "  0.23846203088760376,\n",
       "  0.24372181296348572,\n",
       "  0.23902250826358795,\n",
       "  0.23744064569473267,\n",
       "  0.2333313524723053],\n",
       " 'accuracy': [0.30000001192092896,\n",
       "  0.30000001192092896,\n",
       "  0.30000001192092896,\n",
       "  0.30000001192092896,\n",
       "  0.30000001192092896,\n",
       "  0.30000001192092896,\n",
       "  0.30000001192092896,\n",
       "  0.30000001192092896,\n",
       "  0.30000001192092896,\n",
       "  0.30000001192092896,\n",
       "  0.5333333611488342,\n",
       "  0.3333333432674408,\n",
       "  0.30000001192092896,\n",
       "  0.30000001192092896,\n",
       "  0.5333333611488342,\n",
       "  0.6333333253860474,\n",
       "  0.6666666865348816,\n",
       "  0.699999988079071,\n",
       "  0.699999988079071,\n",
       "  0.7333333492279053,\n",
       "  0.7333333492279053,\n",
       "  0.7333333492279053,\n",
       "  0.7333333492279053,\n",
       "  0.7333333492279053,\n",
       "  0.699999988079071,\n",
       "  0.7333333492279053,\n",
       "  0.8333333134651184,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.7333333492279053,\n",
       "  0.7333333492279053,\n",
       "  0.7333333492279053,\n",
       "  0.7333333492279053,\n",
       "  0.8333333134651184,\n",
       "  0.8333333134651184,\n",
       "  0.800000011920929,\n",
       "  0.8333333134651184,\n",
       "  0.7666666507720947,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.7333333492279053,\n",
       "  0.8333333134651184,\n",
       "  0.8333333134651184,\n",
       "  0.8666666746139526,\n",
       "  0.9666666388511658,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8333333134651184,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.9666666388511658,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8999999761581421,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8333333134651184,\n",
       "  0.8333333134651184,\n",
       "  0.8333333134651184,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.8666666746139526,\n",
       "  0.8333333134651184,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.8666666746139526,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.8666666746139526,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658]}"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "fit(model, train_loader, val_loader, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}